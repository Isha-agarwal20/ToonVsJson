# ğŸš€ JSON vs Toon Format Comparison Tool

A comprehensive tool to compare token usage between JSON and Toon formats for Large Language Models (LLMs). Toon format can reduce token usage by 30-60% compared to JSON, resulting in significant cost savings for LLM applications.

## ğŸ“– What is Toon Format?

**Toon (Token-Oriented Object Notation)** is a compact, human-readable data format designed specifically to minimize token consumption in LLM applications. It achieves this by:

- Eliminating redundant brackets, braces, and quotes
- Using compact array notation with headers
- Removing unnecessary whitespace
- Maintaining full data fidelity and readability

### Format Comparison Example

**JSON Format:**
```json
{
  "users": [
    { "id": 1, "name": "Alice", "role": "admin" },
    { "id": 2, "name": "Bob", "role": "user" }
  ]
}
```

**Toon Format:**
```
users[2]{id,name,role}:
  1,Alice,admin
  2,Bob,user
```

## ğŸ¯ Features

- **JSON to Toon Converter**: Automatically convert JSON data to Toon format
- **Token Counter**: Count tokens using OpenAI's tiktoken library
- **Detailed Comparison**: Compare token usage between JSON (pretty/compact) and Toon formats
- **Cost Analysis**: Estimate cost savings for different LLM models
- **Interactive CLI**: User-friendly command-line interface
- **Batch Processing**: Analyze multiple datasets at once
- **Visual Reports**: Colorful tables and statistics

## ğŸ“¦ Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd ToonVsJson
```

2. Install dependencies:
```bash
npm install
```

## ğŸš€ Usage

### Interactive Mode

Run the interactive CLI tool:
```bash
npm start
```

This provides an interactive menu with options to:
- Convert JSON to Toon format
- Compare token usage
- View example conversions

### Batch Comparison

Run comprehensive comparison on sample datasets:
```bash
npm run compare
```

This will analyze various data structures including:
- User lists
- E-commerce orders
- API responses
- Configuration files
- Nested data structures
- Large datasets

### Test Mode

Run basic tests:
```bash
npm test
```

## ğŸ“Š Token Savings Examples

Based on our sample datasets, here are typical token savings:

| Data Type | JSON Tokens | Toon Tokens | Savings |
|-----------|-------------|-------------|---------|
| User List | 120 | 72 | 40% |
| API Response | 285 | 178 | 37.5% |
| Configuration | 198 | 125 | 36.9% |
| Large Dataset | 3,450 | 2,100 | 39.1% |

## ğŸ’° Cost Impact

For high-volume applications making thousands of API calls:

- **GPT-4**: Save ~$0.012 per 1000 tokens
- **GPT-3.5-turbo**: Save ~$0.0005 per 1000 tokens
- **Claude-3**: Save ~$0.006 per 1000 tokens

With millions of tokens processed daily, savings can be substantial.

## ğŸ—ï¸ Project Structure

```
ToonVsJson/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js           # Interactive CLI tool
â”‚   â”œâ”€â”€ compare.js         # Batch comparison script
â”‚   â”œâ”€â”€ test.js           # Test file
â”‚   â”œâ”€â”€ toonConverter.js  # Toon format converter
â”‚   â””â”€â”€ tokenCounter.js   # Token counting utility
â”œâ”€â”€ data/
â”‚   â””â”€â”€ samples.js        # Sample datasets
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”§ How It Works

### Toon Conversion Rules

1. **Arrays**: `arrayName[count]{keys}: values`
2. **Objects**: Use indentation for nesting
3. **Values**: No quotes unless necessary
4. **Separators**: Comma-separated values
5. **Structure**: Maintain hierarchy through indentation

### Token Counting

The tool uses OpenAI's `tiktoken` library to accurately count tokens for different models:
- GPT-4
- GPT-3.5-turbo
- Claude models

## ğŸ¨ Features Breakdown

### ToonConverter Class

- `jsonToToon()`: Convert JSON to Toon format
- `toonToJson()`: Parse Toon back to JSON
- Handles nested structures, arrays, and mixed data types

### TokenCounter Class

- `countTokens()`: Count tokens in text
- `analyzeTokens()`: Detailed token analysis
- `compareTokens()`: Compare two texts
- `estimateCost()`: Calculate API costs

## ğŸ“ˆ Benefits of Toon Format

1. **Reduced Costs**: 30-60% fewer tokens = lower API costs
2. **Faster Processing**: Less data to process
3. **Higher Context Capacity**: Fit more data in context windows
4. **Maintained Readability**: Still human-readable
5. **Full Fidelity**: No data loss

## ğŸ¤ Contributing

Feel free to contribute by:
- Adding more conversion optimizations
- Supporting additional data structures
- Improving the conversion algorithm
- Adding more comparison metrics

## ğŸ“ Notes

- Toon format is most effective with structured, repetitive data
- Savings vary based on data structure and complexity
- The format maintains full data fidelity
- Compatible with all major LLM providers

## ğŸš¦ Quick Start Example

```javascript
import { ToonConverter } from './src/toonConverter.js';
import { TokenCounter } from './src/tokenCounter.js';

const converter = new ToonConverter();
const counter = new TokenCounter('gpt-4');

const data = {
  users: [
    { id: 1, name: "Alice", role: "admin" },
    { id: 2, name: "Bob", role: "user" }
  ]
};

const json = JSON.stringify(data);
const toon = converter.jsonToToon(data);

console.log(`JSON tokens: ${counter.countTokens(json)}`);
console.log(`Toon tokens: ${counter.countTokens(toon)}`);
```

## ğŸ“š Learn More

- [Toon Format Documentation](https://www.toonparse.com/docs)
- [Token Optimization for LLMs](https://www.toontools.app/docs)
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer)

---

Built with â¤ï¸ to optimize LLM token usage and reduce costs.
